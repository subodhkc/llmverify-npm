# AI Output Verification Workflow Template
# 
# Copy this file to your project's .github/workflows/ directory
# This workflow verifies AI-generated content in your PRs
#
# Prerequisites:
# 1. Install llmverify: npm install llmverify --save-dev
# 2. Add this workflow to .github/workflows/

name: AI Output Verification

on:
  pull_request:
    branches: [main, master]
  workflow_dispatch:
    inputs:
      preset:
        description: 'Verification preset'
        required: false
        default: 'ci'
        type: choice
        options:
          - dev
          - prod
          - strict
          - fast
          - ci

env:
  LLMVERIFY_PRESET: ${{ github.event.inputs.preset || 'ci' }}

jobs:
  verify-ai-output:
    name: Verify AI Output
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18.x'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install llmverify (if not in dependencies)
        run: npm install llmverify --save-dev || true

      - name: Run llmverify doctor
        run: npx llmverify doctor

      - name: Verify AI outputs in changed files
        id: verify
        run: |
          echo "## AI Verification Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Find files that might contain AI output (customize as needed)
          # Example: Check markdown files, JSON responses, etc.
          
          FAILED=0
          
          # Verify any .ai-output.txt files (example pattern)
          for file in $(find . -name "*.ai-output.txt" -o -name "*.ai-response.json" 2>/dev/null); do
            echo "Verifying: $file"
            if ! npx llmverify run --file "$file" --preset $LLMVERIFY_PRESET --output summary; then
              FAILED=1
              echo "[FAIL] **$file**: Verification failed" >> $GITHUB_STEP_SUMMARY
            else
              echo "[OK] **$file**: Passed" >> $GITHUB_STEP_SUMMARY
            fi
          done
          
          # Run general verification on test fixtures if they exist
          if [ -d "tests/fixtures/ai-outputs" ]; then
            for file in tests/fixtures/ai-outputs/*; do
              echo "Verifying fixture: $file"
              if ! npx llmverify run --file "$file" --preset $LLMVERIFY_PRESET --output summary; then
                FAILED=1
                echo "[FAIL] **$file**: Verification failed" >> $GITHUB_STEP_SUMMARY
              else
                echo "[OK] **$file**: Passed" >> $GITHUB_STEP_SUMMARY
              fi
            done
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Preset: \`$LLMVERIFY_PRESET\`" >> $GITHUB_STEP_SUMMARY
          
          if [ $FAILED -eq 1 ]; then
            echo "::error::AI output verification failed"
            exit 1
          fi
          
          echo "[OK] All AI outputs verified successfully"

      - name: Comment on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = process.env.GITHUB_STEP_SUMMARY;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## llmverify AI Verification\n\nPreset: \`${{ env.LLMVERIFY_PRESET }}\`\n\nSee workflow run for details.`
            });
